{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries and modules\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from shutil import copyfile\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import keras,os\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Connect tensorflow to google drive where images are stored.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "HtAsAbuXAm0R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecc79a56-c41d-498e-e68a-d0631ddd1c33"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "source_path =  '/content/drive/MyDrive/image_data'\n",
        "\n",
        "source_path_0 = os.path.join(source_path, 'no_defect')\n",
        "source_path_1 = os.path.join(source_path, 'bubble_defect')\n",
        "source_path_2 = os.path.join(source_path, 'burn_defect')\n",
        "\n",
        "\n",
        "# os.listdir returns a list containing all files under the given path\n",
        "print(f\"There are {len(os.listdir(source_path_0))} images of no_defect.\")\n",
        "print(f\"There are {len(os.listdir(source_path_1))} images of bubble_defect.\")\n",
        "print(f\"There are {len(os.listdir(source_path_2))} images of burn-_defect.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ctvo1VXC-j4p",
        "outputId": "df897252-faa8-46db-a494-4b84a22f57d8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1000 images of no_defect.\n",
            "There are 1000 images of bubble_defect.\n",
            "There are 1000 images of burn-_defect.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define root directory\n",
        "root_dir = '/content/drive/MyDrive/augmented_images'\n",
        "\n",
        "# Empty directory to prevent FileExistsError is the function is run several times\n",
        "if os.path.exists(root_dir):\n",
        "  shutil.rmtree(root_dir)\n",
        "\n",
        "# Create the directories for training and validation datasets\n",
        "def create_train_val_dirs(root_path):\n",
        "\n",
        "  os.makedirs(os.path.join(root_path, 'training'))\n",
        "  os.makedirs(os.path.join(root_path, 'validation'))\n",
        "  os.makedirs(os.path.join(f'{root_path}/training', 'no_defect'))\n",
        "  os.makedirs(os.path.join(f'{root_path}/training', 'bubble_defect'))\n",
        "  os.makedirs(os.path.join(f'{root_path}/training', 'burn_defect'))\n",
        "  os.makedirs(os.path.join(f'{root_path}/validation', 'no_defect'))\n",
        "  os.makedirs(os.path.join(f'{root_path}/validation', 'bubble_defect'))\n",
        "  os.makedirs(os.path.join(f'{root_path}/validation', 'burn_defect'))\n",
        "\n",
        "try:\n",
        "  create_train_val_dirs(root_path=root_dir)\n",
        "except FileExistsError:\n",
        "  print(\"You should not be seeing this since the upper directory is removed beforehand\")"
      ],
      "metadata": {
        "id": "48YLYzvk_exf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing the create_train_val_dirs function\n",
        "\n",
        "for rootdir, dirs, files in os.walk(root_dir):\n",
        "    for subdir in dirs:\n",
        "        print(os.path.join(rootdir, subdir))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ryc6BFsKAggJ",
        "outputId": "4f39b3f5-fc2f-4cd7-cc33-0fe9ed8a5cfc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/augmented_images/training\n",
            "/content/drive/MyDrive/augmented_images/validation\n",
            "/content/drive/MyDrive/augmented_images/training/no_defect\n",
            "/content/drive/MyDrive/augmented_images/training/bubble_defect\n",
            "/content/drive/MyDrive/augmented_images/training/burn_defect\n",
            "/content/drive/MyDrive/augmented_images/validation/no_defect\n",
            "/content/drive/MyDrive/augmented_images/validation/bubble_defect\n",
            "/content/drive/MyDrive/augmented_images/validation/burn_defect\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into the traning and validation directories\n",
        "def split_data(SOURCE_DIR, TRAINING_DIR, VALIDATION_DIR, SPLIT_SIZE):\n",
        "\n",
        "\n",
        "  # Shuffe the images\n",
        "  shuffled_source = random.sample(os.listdir(SOURCE_DIR), len(os.listdir(SOURCE_DIR)))\n",
        "\n",
        "  training_number = int(len(shuffled_source) * SPLIT_SIZE)\n",
        "\n",
        "  i = 0\n",
        "  target = TRAINING_DIR\n",
        "\n",
        "  for item in shuffled_source:\n",
        "    item_source = os.path.join(SOURCE_DIR, item)\n",
        "    if  os.path.getsize(item_source) == 0:\n",
        "      print(f'{item} is zero length, so ignoring.')\n",
        "    else:\n",
        "      copyfile(item_source, os.path.join(target, item))\n",
        "      i += 1\n",
        "\n",
        "      # Switch copy target to validation:\n",
        "      if i == training_number:\n",
        "        target = VALIDATION_DIR\n",
        "\n"
      ],
      "metadata": {
        "id": "vkUhQcygA73Z"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the split_data function\n",
        "\n",
        "# Define paths for training and validation directories\n",
        "\n",
        "NO_DEFECT_SOURCE_DIR = \"/content/drive/MyDrive/image_data/no_defect/\"\n",
        "BUBBLE_SOURCE_DIR = \"/content/drive/MyDrive/image_data/bubble_defect/\"\n",
        "BURN_SOURCE_DIR = \"/content/drive/MyDrive/image_data/burn_defect/\"\n",
        "\n",
        "TRAINING_DIR = \"/content/drive/MyDrive/augmented_images/training/\"\n",
        "VALIDATION_DIR = \"/content/drive/MyDrive/augmented_images/validation/\"\n",
        "\n",
        "TRAINING_NO_DEFECT_DIR = os.path.join(TRAINING_DIR, \"no_defect/\")\n",
        "VALIDATION_NO_DEFECT_DIR = os.path.join(VALIDATION_DIR, \"no_defect/\")\n",
        "\n",
        "TRAINING_BUBBLE_DEFECT_DIR = os.path.join(TRAINING_DIR, \"bubble_defect/\")\n",
        "VALIDATION_BUBBLE_DEFECT_DIR = os.path.join(VALIDATION_DIR, \"bubble_defect/\")\n",
        "\n",
        "TRAINING_BURN_DEFECT_DIR = os.path.join(TRAINING_DIR, \"burn_defect/\")\n",
        "VALIDATION_BURN_DEFECT_DIR = os.path.join(VALIDATION_DIR, \"burn_defect/\")\n",
        "\n",
        "# Empty directories in case you run this cell multiple times\n",
        "if len(os.listdir(TRAINING_NO_DEFECT_DIR)) > 0:\n",
        "  for file in os.scandir(TRAINING_NO_DEFECT_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TRAINING_BUBBLE_DEFECT_DIR)) > 0:\n",
        "  for file in os.scandir(TRAINING_BUBBLE_DEFECT_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TRAINING_BURN_DEFECT_DIR)) > 0:\n",
        "  for file in os.scandir(TRAINING_BURN_DEFECT_DIR):\n",
        "    os.remove(file.path)\n",
        "\n",
        "\n",
        "if len(os.listdir(VALIDATION_NO_DEFECT_DIR)) > 0:\n",
        "  for file in os.scandir(VALIDATION_NO_DEFECT_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(VALIDATION_BUBBLE_DEFECT_DIR)) > 0:\n",
        "  for file in os.scandir(VALIDATION_BUBBLE_DEFECT_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(VALIDATION_BURN_DEFECT_DIR)) > 0:\n",
        "  for file in os.scandir(VALIDATION_BURN_DEFECT_DIR):\n",
        "    os.remove(file.path)\n",
        "\n",
        "\n",
        "# Define the proportion of images used for training and validation\n",
        "split_size = .9\n",
        "\n",
        "# Call the function to split the data\n",
        "\n",
        "split_data(NO_DEFECT_SOURCE_DIR, TRAINING_NO_DEFECT_DIR, VALIDATION_NO_DEFECT_DIR, split_size)\n",
        "split_data(BUBBLE_SOURCE_DIR, TRAINING_BUBBLE_DEFECT_DIR, VALIDATION_BUBBLE_DEFECT_DIR, split_size)\n",
        "split_data(BURN_SOURCE_DIR, TRAINING_BURN_DEFECT_DIR, VALIDATION_BURN_DEFECT_DIR, split_size)\n",
        "\n",
        "# Check that the number of images matches the expected output\n",
        "\n",
        "\n",
        "print(f\"\\n\\nOriginal no_defect's directory has {len(os.listdir(NO_DEFECT_SOURCE_DIR))} images\")\n",
        "print(f\"Original bubble_defect's directory has {len(os.listdir(BUBBLE_SOURCE_DIR))} images\\n\")\n",
        "print(f\"Original burn_defect's directory has {len(os.listdir(BURN_SOURCE_DIR))} images\\n\")\n",
        "\n",
        "# Training images\n",
        "print(f\"There are {len(os.listdir(TRAINING_NO_DEFECT_DIR))} images of no_defect for training\")\n",
        "print(f\"There are {len(os.listdir(TRAINING_BUBBLE_DEFECT_DIR))} images of bubble_defect for training\")\n",
        "print(f\"There are {len(os.listdir(TRAINING_BURN_DEFECT_DIR))} images of burn_defect for training\")\n",
        "\n",
        "# Validation images\n",
        "print(f\"There are {len(os.listdir(VALIDATION_NO_DEFECT_DIR))} images of no_defect for validation\")\n",
        "print(f\"There are {len(os.listdir(VALIDATION_BUBBLE_DEFECT_DIR))} images of bubble_defect for validation\")\n",
        "print(f\"There are {len(os.listdir(VALIDATION_BURN_DEFECT_DIR))} images of burn_defect for validation\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXPo-tzuBAM6",
        "outputId": "2dcd1c9c-9aa9-47e0-ce04-45654d6134aa"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Original no_defect's directory has 1000 images\n",
            "Original bubble_defect's directory has 1000 images\n",
            "\n",
            "Original burn_defect's directory has 1000 images\n",
            "\n",
            "There are 900 images of no_defect for training\n",
            "There are 900 images of bubble_defect for training\n",
            "There are 900 images of burn_defect for training\n",
            "There are 100 images of no_defect for validation\n",
            "There are 100 images of bubble_defect for validation\n",
            "There are 100 images of burn_defect for validation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create generators to flow images from directory into VGG16 network\n",
        "\n",
        "def train_val_generators(TRAINING_DIR, VALIDATION_DIR):\n",
        "\n",
        "\n",
        "  # Instantiate the ImageDataGenerator and normalise image pixel values for the training dataset. \n",
        "  train_datagen = ImageDataGenerator(rescale = 1/255.)\n",
        "\n",
        " # Flow images from training image directory and resize to 224 x 224px\n",
        "  train_generator = train_datagen.flow_from_directory(directory=TRAINING_DIR,\n",
        "                                                      batch_size=45,\n",
        "                                                      class_mode='categorical',\n",
        "                                                      target_size=(224, 224))\n",
        "\n",
        "  # Instantiate the ImageDataGenerator and normalise image pixel values for the validation dataset. \n",
        "  validation_datagen = ImageDataGenerator(rescale = 1/255.)\n",
        "\n",
        "   # Flow images from validation image directory and resize to 224 x 224px\n",
        "  validation_generator = validation_datagen.flow_from_directory(directory=VALIDATION_DIR,\n",
        "                                                                batch_size=5,\n",
        "                                                                class_mode='categorical',\n",
        "                                                                target_size=(224, 224))\n",
        "\n",
        "  return train_generator, validation_generator"
      ],
      "metadata": {
        "id": "TD5l9EqxHhjm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the generators output the correct quantity of images\n",
        "train_generator, validation_generator = train_val_generators(TRAINING_DIR, VALIDATION_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHddl136Hps7",
        "outputId": "2f696f1e-6b25-468d-eb34-a3adcdee8e82"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2700 images belonging to 3 classes.\n",
            "Found 300 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the VGG16 Model\n",
        "\n",
        "def VGG16():\n",
        "  \n",
        "  # Initialise the network weights\n",
        "  initializer = tf.keras.initializers.RandomNormal(mean=0., stddev=1.)\n",
        " \n",
        "  # Build the VGG16 Network\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "  model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "  model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "  model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "  model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "  model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "  model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(units=4096,activation=\"relu\", kernel_initializer=initializer))\n",
        "  model.add(Dense(units=4096,activation=\"relu\", kernel_initializer=initializer))\n",
        "  model.add(Dense(units=3, activation=\"softmax\", kernel_initializer=initializer))\n",
        "\n",
        "  #Compile the network\n",
        "  from keras.optimizers import Adam\n",
        "  \n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001),\n",
        "                     loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "                     metrics=[tf.keras.metrics.Accuracy(),\n",
        "                              tf.keras.metrics.Precision(),\n",
        "                              tf.keras.metrics.Recall()\n",
        "                             ]\n",
        "                                                  )\n",
        "      \n",
        "  return model   \n",
        "   \n",
        "  "
      ],
      "metadata": {
        "id": "ZmW-GH6uGNQv"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Instantiate and train the VGG16 model\n",
        "\n",
        "model = VGG16()\n",
        "\n",
        "\n",
        "history = model.fit(train_generator,\n",
        "                    steps_per_epoch=20,\n",
        "                    epochs=20,\n",
        "                    verbose=1,\n",
        "                    validation_data=validation_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0J_e60THITU",
        "outputId": "00ea17dd-ca8d-4129-d67c-a428cb5ea6ce"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "20/20 [==============================] - 23s 800ms/step - loss: 163.2552 - accuracy: 0.5037 - precision_1: 0.3678 - recall_1: 0.3678 - val_loss: 52.6099 - val_accuracy: 0.5689 - val_precision_1: 0.5900 - val_recall_1: 0.5900\n",
            "Epoch 2/20\n",
            "20/20 [==============================] - 15s 748ms/step - loss: 26.6885 - accuracy: 0.5415 - precision_1: 0.6522 - recall_1: 0.6522 - val_loss: 6.9696 - val_accuracy: 0.5633 - val_precision_1: 0.7733 - val_recall_1: 0.7733\n",
            "Epoch 3/20\n",
            "20/20 [==============================] - 15s 755ms/step - loss: 4.4604 - accuracy: 0.5900 - precision_1: 0.8456 - recall_1: 0.8456 - val_loss: 0.9134 - val_accuracy: 0.6311 - val_precision_1: 0.9567 - val_recall_1: 0.9567\n",
            "Epoch 4/20\n",
            "20/20 [==============================] - 16s 768ms/step - loss: 1.6406 - accuracy: 0.5896 - precision_1: 0.9222 - recall_1: 0.9222 - val_loss: 1.5268 - val_accuracy: 0.5833 - val_precision_1: 0.9200 - val_recall_1: 0.9200\n",
            "Epoch 5/20\n",
            "20/20 [==============================] - 16s 776ms/step - loss: 1.2493 - accuracy: 0.5485 - precision_1: 0.9233 - recall_1: 0.9233 - val_loss: 2.5260 - val_accuracy: 0.5633 - val_precision_1: 0.8600 - val_recall_1: 0.8600\n",
            "Epoch 6/20\n",
            "20/20 [==============================] - 16s 776ms/step - loss: 1.4638 - accuracy: 0.5922 - precision_1: 0.9222 - recall_1: 0.9222 - val_loss: 1.3533 - val_accuracy: 0.6811 - val_precision_1: 0.9300 - val_recall_1: 0.9300\n",
            "Epoch 7/20\n",
            "20/20 [==============================] - 15s 765ms/step - loss: 2.7461 - accuracy: 0.5974 - precision_1: 0.8711 - recall_1: 0.8711 - val_loss: 2.0326 - val_accuracy: 0.6867 - val_precision_1: 0.9100 - val_recall_1: 0.9100\n",
            "Epoch 8/20\n",
            "20/20 [==============================] - 15s 767ms/step - loss: 3.4281 - accuracy: 0.6485 - precision_1: 0.8721 - recall_1: 0.8711 - val_loss: 1.1746 - val_accuracy: 0.7344 - val_precision_1: 0.9567 - val_recall_1: 0.9567\n",
            "Epoch 9/20\n",
            "20/20 [==============================] - 15s 763ms/step - loss: 1.1000 - accuracy: 0.6722 - precision_1: 0.9467 - recall_1: 0.9467 - val_loss: 0.4860 - val_accuracy: 0.6722 - val_precision_1: 0.9667 - val_recall_1: 0.9667\n",
            "Epoch 10/20\n",
            "20/20 [==============================] - 16s 775ms/step - loss: 1.7660 - accuracy: 0.6396 - precision_1: 0.9278 - recall_1: 0.9278 - val_loss: 4.7028 - val_accuracy: 0.6144 - val_precision_1: 0.8200 - val_recall_1: 0.8200\n",
            "Epoch 11/20\n",
            "20/20 [==============================] - 16s 777ms/step - loss: 3.1701 - accuracy: 0.6593 - precision_1: 0.8989 - recall_1: 0.8989 - val_loss: 2.2332 - val_accuracy: 0.7244 - val_precision_1: 0.8933 - val_recall_1: 0.8933\n",
            "Epoch 12/20\n",
            "20/20 [==============================] - 16s 777ms/step - loss: 0.5927 - accuracy: 0.7156 - precision_1: 0.9622 - recall_1: 0.9622 - val_loss: 0.1095 - val_accuracy: 0.7200 - val_precision_1: 0.9900 - val_recall_1: 0.9900\n",
            "Epoch 13/20\n",
            "20/20 [==============================] - 15s 767ms/step - loss: 0.9796 - accuracy: 0.7100 - precision_1: 0.9622 - recall_1: 0.9622 - val_loss: 4.5598 - val_accuracy: 0.7311 - val_precision_1: 0.8733 - val_recall_1: 0.8733\n",
            "Epoch 14/20\n",
            "20/20 [==============================] - 15s 763ms/step - loss: 0.8944 - accuracy: 0.7330 - precision_1: 0.9600 - recall_1: 0.9600 - val_loss: 0.2652 - val_accuracy: 0.7322 - val_precision_1: 0.9800 - val_recall_1: 0.9800\n",
            "Epoch 15/20\n",
            "20/20 [==============================] - 15s 761ms/step - loss: 0.4546 - accuracy: 0.6993 - precision_1: 0.9644 - recall_1: 0.9644 - val_loss: 2.3711 - val_accuracy: 0.7311 - val_precision_1: 0.9167 - val_recall_1: 0.9167\n",
            "Epoch 16/20\n",
            "20/20 [==============================] - 15s 763ms/step - loss: 0.7418 - accuracy: 0.7256 - precision_1: 0.9556 - recall_1: 0.9556 - val_loss: 0.6662 - val_accuracy: 0.7733 - val_precision_1: 0.9700 - val_recall_1: 0.9700\n",
            "Epoch 17/20\n",
            "20/20 [==============================] - 16s 774ms/step - loss: 1.0166 - accuracy: 0.7374 - precision_1: 0.9500 - recall_1: 0.9500 - val_loss: 0.2861 - val_accuracy: 0.7656 - val_precision_1: 0.9833 - val_recall_1: 0.9833\n",
            "Epoch 18/20\n",
            "20/20 [==============================] - 16s 782ms/step - loss: 0.2068 - accuracy: 0.7207 - precision_1: 0.9878 - recall_1: 0.9878 - val_loss: 0.2554 - val_accuracy: 0.7078 - val_precision_1: 0.9833 - val_recall_1: 0.9833\n",
            "Epoch 19/20\n",
            "20/20 [==============================] - 15s 764ms/step - loss: 0.5270 - accuracy: 0.6907 - precision_1: 0.9667 - recall_1: 0.9667 - val_loss: 0.2120 - val_accuracy: 0.7056 - val_precision_1: 0.9800 - val_recall_1: 0.9800\n",
            "Epoch 20/20\n",
            "20/20 [==============================] - 16s 778ms/step - loss: 0.2845 - accuracy: 0.7063 - precision_1: 0.9856 - recall_1: 0.9856 - val_loss: 0.0866 - val_accuracy: 0.7056 - val_precision_1: 0.9900 - val_recall_1: 0.9900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect performance metrics from the VGG16 model\n",
        "\n",
        "acc=history.history['accuracy']\n",
        "val_acc=history.history['val_accuracy']\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs=range(len(acc)) # Get number of epochs\n",
        "\n",
        "# Plot training and validation accuracy per epoch\n",
        "plt.plot(epochs, acc, 'r', label=\"Training Accuracy\")\n",
        "plt.plot(epochs, val_acc, 'b', label=\"Validation Accuracy\")\n",
        "plt.legend(loc='lower right')\n",
        "plt.yticks([0.0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
        "plt.savefig('img.svg')\n",
        "plt.ylim(0,1)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# Plot training and validation loss per epoch\n",
        "#plt.plot(epochs, loss, 'r', \"Training Loss\")\n",
        "#plt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n",
        "#plt.show()\n"
      ],
      "metadata": {
        "id": "bGN-tkWfHczD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# convert the history.history dict to a pandas DataFrame:     \n",
        "hist_df = pd.DataFrame(history.history) \n",
        "hist_df\n"
      ],
      "metadata": {
        "id": "fvljlCP1MDAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confusion Matrix"
      ],
      "metadata": {
        "id": "kHF62DDCvkjT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TEST_DIR = \"/content/drive/MyDrive/test_data\"\n",
        "\n",
        "# Instantiate the ImageDataGenerator and normalise image pixel values for the test dataset. \n",
        "test_datagen = ImageDataGenerator(rescale = 1/255.)\n",
        "\n",
        "# Flow images from validation image directory and resize to 224 x 224px\n",
        "test_generator = test_datagen.flow_from_directory(directory=TEST_DIR,\n",
        "                                                                batch_size=5,\n",
        "                                                                class_mode='categorical',\n",
        "                                                                target_size=(224, 224))\n",
        "\n",
        "predictions = model.predict(test_generator)"
      ],
      "metadata": {
        "id": "2lRyhGcZz4iW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "preds_cls_idx = predictions.argmax(axis=1)\n",
        "idx_to_cls = {v: k for k, v in train_generator.class_indices.items()}\n",
        "preds_cls = np.vectorize(idx_to_cls.get)(preds_cls_idx)\n",
        "filenames_to_cls = list(zip(test_generator.filenames, preds_cls))\n",
        "\n",
        "filenames_to_cls[:300]"
      ],
      "metadata": {
        "id": "dFhobkBTv3Em"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "results = pd.DataFrame(filenames_to_cls)\n",
        "results"
      ],
      "metadata": {
        "id": "EXWFDVZc0sHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Juvvn_U-1xQ3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}